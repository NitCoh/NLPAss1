{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3+"
    },
    "colab": {
      "name": "part1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmdROlJJNtLk",
        "colab_type": "code",
        "outputId": "cf3444ff-d834-47a5-a734-d13125845c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install justext"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: justext in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: lxml>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from justext) (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWh_5rVkOyMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import justext\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ8c3aHnlDx5",
        "colab_type": "code",
        "outputId": "8f9d6599-5b9c-4180-96fc-7248cc09290c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo6kW-6tyCPg",
        "colab_type": "text"
      },
      "source": [
        "1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eDGnqmpRq9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_txt(txt,top):\n",
        "  most_common_words = [word for (word,f) in collections.Counter(txt).most_common(top)]\n",
        "  return ''.join([word if word in most_common_words or word=='N' else '<unk>' for word in txt])\n",
        "def replace_numbers(txt):\n",
        "  #TODO:: Check replace numbers RegEx.\n",
        "  num_format = re.compile(\"^[\\-]?[1-9][0-9]*\\.?[0-9]+$\")\n",
        "  return \"\".join([word if not re.match(num_format,word) else 'N' for word in txt])\n",
        "def remove_punc(txt):\n",
        "  without_punc = \"\".join([ c if c not in '.,:;?!@#*&%$<>' else '' for c in txt])\n",
        "  return without_punc.replace(\"  \",\" \")\n",
        "def tokenize(txt):\n",
        "  return \" \".join(nltk.word_tokenize(txt))\n",
        "def segment_sents(txt):\n",
        "  return \"\\n\".join(nltk.sent_tokenize(txt))\n",
        "def lower_txt(txt):\n",
        "  return txt.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2KptyAiOyM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ptb_preprocess(filenames, top=10000):\n",
        "  for filename in filenames:\n",
        "    with open(filename) as myfile:\n",
        "      \n",
        "\n",
        "      txt_file =  myfile.read().replace('\\n',' ')\n",
        "      paragraphs = justext.justext(txt_file, justext.get_stoplist(\"English\"))\n",
        "      raw_text = \"\\n\".join([p.text for p in paragraphs if not p.is_boilerplate])\n",
        "\n",
        "\n",
        "      # raw_text = lower_txt(raw_text)\n",
        "      # raw_text = segment_sents(raw_text)\n",
        "      # print('segment_sents')\n",
        "      # print(raw_text[:200])\n",
        "      # raw_text = remove_punc(raw_text)\n",
        "      # print('remove_punkt')\n",
        "      # print(raw_text[:200])\n",
        "      # raw_text = tokenize(raw_text)\n",
        "      # print('tokenize')\n",
        "      # print(raw_text[:200])\n",
        "      # raw_text = replace_numbers(raw_text)\n",
        "      # print('replace_numbers')\n",
        "      # print(raw_text[:200])\n",
        "      # raw_text = top_txt(raw_text,top)\n",
        "      # print('top_txt')\n",
        "      # print(raw_text[:200])\n",
        "\n",
        "      raw_text = top_txt(raw_text,top)\n",
        "      raw_text = replace_numbers(raw_text)\n",
        "      raw_text = tokenize(raw_text)\n",
        "      raw_text = segment_sents(raw_text)\n",
        "      raw_text = remove_punc(raw_text)\n",
        "      raw_text = lower_txt(raw_text)\n",
        "      \n",
        "      \n",
        "      new_filename = filename+'.out'\n",
        "      #print(new_filename)\n",
        "      with open(new_filename, \"w\") as text_file:\n",
        "        text_file.write(raw_text)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNWfFRBhQCz2",
        "colab_type": "code",
        "outputId": "f57df18a-4558-44c8-c0a7-f9cbcc56178e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-25 18:56:16--  https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4573338 (4.4M) [text/plain]\n",
            "Saving to: ‘shakespeare_input.txt.3’\n",
            "\n",
            "shakespeare_input.t 100%[===================>]   4.36M  3.83MB/s    in 1.1s    \n",
            "\n",
            "2019-12-25 18:56:17 (3.83 MB/s) - ‘shakespeare_input.txt.3’ saved [4573338/4573338]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts1OWn9yE5hx",
        "colab_type": "text"
      },
      "source": [
        "1.1.1 Discussion: According to the descripted above if we apply the conventions of Penn Treebank, we shall give independent meaning for every word after the tokenization. Also, if we use character-level language model, we shall get another definition - morphological, because now we care about structure of the word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1twpt96H3Ja",
        "colab_type": "text"
      },
      "source": [
        "1.1.2 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl1uQDDlH55T",
        "colab_type": "code",
        "outputId": "9501007b-491c-4bce-d4e8-2bb1cb474ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "!tar zxvf simple-examples.tgz\n",
        "\n",
        "!ls simple-examples/data\n",
        "!mv ./simple-examples/data ../data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-25 18:56:19--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz.3’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  19.4MB/s    in 1.7s    \n",
            "\n",
            "2019-12-25 18:56:21 (19.4 MB/s) - ‘simple-examples.tgz.3’ saved [34869662/34869662]\n",
            "\n",
            "./\n",
            "./simple-examples/\n",
            "./simple-examples/data/\n",
            "./simple-examples/data/ptb.test.txt\n",
            "./simple-examples/data/ptb.train.txt\n",
            "./simple-examples/data/ptb.valid.txt\n",
            "./simple-examples/data/README\n",
            "./simple-examples/data/ptb.char.train.txt\n",
            "./simple-examples/data/ptb.char.test.txt\n",
            "./simple-examples/data/ptb.char.valid.txt\n",
            "./simple-examples/models/\n",
            "./simple-examples/models/swb.ngram.model\n",
            "./simple-examples/models/swb.rnn.model\n",
            "./simple-examples/models/README\n",
            "./simple-examples/rnnlm-0.2b/\n",
            "./simple-examples/rnnlm-0.2b/CHANGE.log\n",
            "./simple-examples/rnnlm-0.2b/FAQ.txt\n",
            "./simple-examples/rnnlm-0.2b/convert.c\n",
            "./simple-examples/rnnlm-0.2b/makefile\n",
            "./simple-examples/rnnlm-0.2b/rnnlm.cpp\n",
            "./simple-examples/rnnlm-0.2b/rnnlmlib.cpp\n",
            "./simple-examples/rnnlm-0.2b/rnnlmlib.h\n",
            "./simple-examples/rnnlm-0.2b/prob.c\n",
            "./simple-examples/rnnlm-0.2b/test\n",
            "./simple-examples/rnnlm-0.2b/train\n",
            "./simple-examples/rnnlm-0.2b/valid\n",
            "./simple-examples/rnnlm-0.2b/example.sh\n",
            "./simple-examples/rnnlm-0.2b/example.output\n",
            "./simple-examples/rnnlm-0.2b/COPYRIGHT.txt\n",
            "./simple-examples/1-train/\n",
            "./simple-examples/1-train/train.sh\n",
            "./simple-examples/1-train/test.sh\n",
            "./simple-examples/1-train/README\n",
            "./simple-examples/3-combination/\n",
            "./simple-examples/3-combination/train.sh\n",
            "./simple-examples/3-combination/test.sh\n",
            "./simple-examples/3-combination/README\n",
            "./simple-examples/2-nbest-rescore/\n",
            "./simple-examples/2-nbest-rescore/lattices/\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127040_127488.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127513_127835.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_127865_128175.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_128188_128447.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/AMI-3E0501_u3005_128490_129032.lat.gz\n",
            "./simple-examples/2-nbest-rescore/lattices/nbest.sh\n",
            "./simple-examples/2-nbest-rescore/lattices/nbest/\n",
            "./simple-examples/2-nbest-rescore/lattices/latlist\n",
            "./simple-examples/2-nbest-rescore/README\n",
            "./simple-examples/2-nbest-rescore/getbest.c\n",
            "./simple-examples/2-nbest-rescore/gettext.c\n",
            "./simple-examples/2-nbest-rescore/makenbest.c\n",
            "./simple-examples/2-nbest-rescore/makenbest\n",
            "./simple-examples/2-nbest-rescore/gettext\n",
            "./simple-examples/2-nbest-rescore/getbest\n",
            "./simple-examples/5-one-iter/\n",
            "./simple-examples/5-one-iter/test.sh\n",
            "./simple-examples/5-one-iter/train.sh\n",
            "./simple-examples/5-one-iter/README\n",
            "./simple-examples/6-recovery-during-training/\n",
            "./simple-examples/6-recovery-during-training/test.sh\n",
            "./simple-examples/6-recovery-during-training/train.sh\n",
            "./simple-examples/6-recovery-during-training/README\n",
            "./simple-examples/7-dynamic-evaluation/\n",
            "./simple-examples/7-dynamic-evaluation/test.sh\n",
            "./simple-examples/7-dynamic-evaluation/train.sh\n",
            "./simple-examples/7-dynamic-evaluation/README\n",
            "./simple-examples/temp/\n",
            "./simple-examples/8-direct/\n",
            "./simple-examples/8-direct/train.sh\n",
            "./simple-examples/8-direct/test.sh\n",
            "./simple-examples/8-direct/README\n",
            "./simple-examples/4-data-generation/\n",
            "./simple-examples/4-data-generation/train.sh\n",
            "./simple-examples/4-data-generation/test.sh\n",
            "./simple-examples/4-data-generation/README\n",
            "./simple-examples/9-char-based-lm/\n",
            "./simple-examples/9-char-based-lm/test.sh\n",
            "./simple-examples/9-char-based-lm/train.sh\n",
            "./simple-examples/9-char-based-lm/README\n",
            "ptb.char.test.txt   ptb.char.valid.txt\tptb.train.txt  README\n",
            "ptb.char.train.txt  ptb.test.txt\tptb.valid.txt\n",
            "mv: cannot move './simple-examples/data' to '../data/data': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VgRPhj407Tc",
        "colab_type": "code",
        "outputId": "e1cfc7ea-26c3-4fdf-8aef-3ce70aec2554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recipes_dataset\t\t shakespeare_input.txt.2  simple-examples.tgz.1\n",
            "sample_data\t\t shakespeare_input.txt.3  simple-examples.tgz.2\n",
            "shakespeare_input.txt\t simple-examples\t  simple-examples.tgz.3\n",
            "shakespeare_input.txt.1  simple-examples.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u-G63oDV2MZ",
        "colab_type": "code",
        "outputId": "3c577b1a-5d01-4970-ef1b-08d77945fce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(remove_punc('hello, you, hello').split()))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_9519iByOPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_token(txt):\n",
        "  txt = txt.lower()\n",
        "  return len(nltk.word_tokenize(txt))\n",
        "def num_char(txt):\n",
        "  return len(''.join(txt.split()))\n",
        "def dist_words(txt): #vocabulary size\n",
        "  txt = txt.lower()\n",
        "  return len(set(remove_punc(txt).split()))\n",
        "def topN_words(txt,N):\n",
        "  most_common_words = ' '.join([word for (word,f) in collections.Counter(txt).most_common(N)])\n",
        "  return num_tokenize(most_common_words)\n",
        "def token_type_ratio(txt):\n",
        "  return num_token(txt)/dist_words(txt)\n",
        "\n",
        "def types_oov(txt_dev,txt_train): #Out Of Vocabulary \n",
        "    txt_dev = txt_dev.lower()\n",
        "    text_dev_set = set(remove_punc(txt_dev).split())\n",
        "    txt_train = txt_train.lower()\n",
        "    text_train_set = set(remove_punc(txt_train).split())\n",
        "    return len(tex_dev_set.difference(text_train_set))\n",
        "def avg_sd_char_token(txt):\n",
        "  total_chars = sum( [len(w) for w in nltk.word_tokenize(txt)])\n",
        "  avg =  total_chars/num_token(txt)\n",
        "\n",
        "  total_avg_chars = sum( [len(w)-avg for w in nltk.word_tokenize(txt)])\n",
        "  sd =  total_chars/num_token(txt)\n",
        "  return avg,sd\n",
        "\n",
        "def dist_n_gram_words(txt,n=[2,3,4]):\n",
        "  txt = txt.lower()\n",
        "  txt = nltk.word_tokenize(txt)\n",
        "  ans = {}\n",
        "  for i in n:\n",
        "    ans[i] = diff_grams(txt,i)\n",
        "  return ans\n",
        "\n",
        "def dist_n_gram_chars(txt,n=range(1,8)):\n",
        "  ans = {}\n",
        "  for i in n:\n",
        "    ans[i] = diff_grams(txt,i)\n",
        "  return ans\n",
        "\n",
        "def diff_grams(txt,n):\n",
        "  s = set()\n",
        "  gram = list(range(0,n))\n",
        "  while gram[-1]!=len(txt):\n",
        "    next_gram = tuple([txt[g] for g in gram])\n",
        "    s.add(next_gram)\n",
        "    gram = [g+1 for g in gram]\n",
        "  return len(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceYy9o1urbi0",
        "colab_type": "code",
        "outputId": "75227b68-2163-4f3d-b1e2-719168d19fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# you need matplotlib version 1.4 or above\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "print(matplotlib.__version__)\n",
        "%matplotlib inline\n",
        "def power_law_rule(corpus):\n",
        "  corpus = lower_txt(corpus)\n",
        "  corpus = tokenize(corpus)\n",
        "  plt.loglog([val for word,val in collections.Counter(corpus).most_common(4000)])\n",
        "  plt.xlabel('rank')\n",
        "  plt.ylabel('frequency');"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY9AIs-GKmGV",
        "colab_type": "code",
        "outputId": "64bd4e3b-0cc3-4270-a0b8-aae54be0a7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "import os\n",
        "\n",
        "dir = '../data'\n",
        "for filename in os.listdir(dir):\n",
        "  with open(dir+'/'+ filename,'r') as file:\n",
        "      data = file.read()\n",
        "      power_law_rule(data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7bb2297ad173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mpower_law_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '../data/data'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNooFEREpI1CQURE2vx/wF9aRlFjmbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikQJvQfnt6Ba",
        "colab_type": "text"
      },
      "source": [
        "1.2 n-gram Word Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YzeX7KNdYhPL",
        "colab": {}
      },
      "source": [
        "#how to calculate the freq of h*w\n",
        "#how to calculate the freq of w.\n",
        "\n",
        "from collections import Counter,defaultdict\n",
        "import math\n",
        "from functools import reduce\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class LangModell:\n",
        "  @abstractmethod\n",
        "  def predict_next_word(self,prev_words):\n",
        "    pass\n",
        "  @abstractmethod\n",
        "  def evaluate_next_word(self,prev_word):\n",
        "    pass\n",
        "  \n",
        "class n_gram_model(LangModell):\n",
        "  def __init__(self,gamma=0):\n",
        "    self.outlm = {}\n",
        "    self.freq_words = collections.Counter()\n",
        "    self.gamma = gamma\n",
        "\n",
        "  def train_model(self, dataset,n,pre_process,tokenize=True):\n",
        "    lm = defaultdict(Counter)\n",
        "    if pre_process == True :\n",
        "      ptb_preprocess([dataset])\n",
        "    filename =  dataset if pre_process == False else dataset+'.out'\n",
        "    with open(filename) as file:\n",
        "      data = file.read()\n",
        "      if tokenize:\n",
        "        data = nltk.word_tokenize(data)\n",
        "    self.freq_words = collections.Counter(data)\n",
        "    n = n-1\n",
        "    if tokenize:\n",
        "      pad = [\"~\"] * n\n",
        "    else:\n",
        "      pad = '~' * n\n",
        "    data = pad + data\n",
        "    for i in range(len(data)-n):\n",
        "        history, word = tuple(data[i:i+n]), data[i+n]\n",
        "        lm[history][word]+=1\n",
        "\n",
        "    def normalize(counter):\n",
        "\n",
        "       #(c+gamma)/(N+B*gamma) according to the lidstone estimator from the NLTK docs.\n",
        "      \n",
        "        N = float(sum(counter.values()))\n",
        "        B = len(counter)\n",
        "        return { word : c+self.gamma/(N+B*self.gamma) for word,c in counter.items()}\n",
        "\n",
        "    self.freq_words= {word:freq/len(data) for word,freq in self.freq_words.items()}\n",
        "    self.not_normalized_lm = lm\n",
        "    self.outlm = {hist:normalize(cntr) for hist, cntr in lm.items()}\n",
        "\n",
        "  def predict_next_word(self, prev_words,chars=False):\n",
        "    if chars:\n",
        "      possible_words = self.outln(tuple(prev_words))\n",
        "    else:\n",
        "      possible_words =  self.outlm[tuple(nltk.word_tokenize(prev_words.lower()))]\n",
        "    next_word, prob = max(possible_words.items(), key=lambda x:x[1])\n",
        "    return next_word,prob\n",
        "\n",
        "  def evaluate_next_word(self, prev_words,next_word):\n",
        "    prev_words = tuple(nltk.word_tokenize(prev_words.lower()))\n",
        "    if prev_words in self.outlm:\n",
        "      counter = self.not_normalized_lm[prev_words]\n",
        "      N = float(sum(counter.values()))\n",
        "      B = len(counter)\n",
        "      c = self.not_normalized_lm[prev_words][next_word]\n",
        "      return (c+self.gamma)/(N+B*self.gamma) \n",
        "    return 0\n",
        "\n",
        "def perplexity(model,test_filename,pre_process=True,n=2):\n",
        "  if pre_process == True:\n",
        "    ptb_preprocess([test_filename])\n",
        "    filename = test_filename+'.out'\n",
        "  else:\n",
        "    filename=test_filename\n",
        "  with open(filename) as file:\n",
        "    data = nltk.word_tokenize(file.read())\n",
        "  answer = 1\n",
        "  #print(\"Number of tested tokens :\", len(data))\n",
        "  for i in range(len(data) - (n+1)):\n",
        "    prev_words = ' '.join(data[i:i+n-1])\n",
        "    next_word = data[i+n-1]\n",
        "    eval = model.evaluate_next_word(prev_words,next_word)\n",
        "    #print(eval)\n",
        "    if eval!=0:\n",
        "      eval = (1/eval) **(1/len(data))\n",
        "      answer*= eval\n",
        "  return answer  \n",
        "\n",
        "def cross_entropy(model,test_filename,pre_process=True):\n",
        "  #TODO: validate how to calculate it\n",
        "  if pre_process == True:\n",
        "    ptb_preprocess([test_filename])\n",
        "    filename = test_filename+'.out'\n",
        "  else:\n",
        "    filename = test_filename\n",
        "  with open(filename) as file:\n",
        "    data = nltk.word_tokenize(file.read())\n",
        "  return sum( [math.log(model.freq_words[word],2)/len(data) for word in data] )\n",
        "\n",
        "def train_word_gen(dataset,n=2,gamma=0):\n",
        "  lm = n_gram_model(gamma=gamma)\n",
        "  lm.train_model(dataset,n,False)\n",
        "  return lm\n",
        "\n",
        "def train_word_lm(dataset,n=2,tokenize=True):\n",
        "  lm = n_gram_model()\n",
        "  lm.train_model(dataset,n,False,tokenize=tokenize)\n",
        "  return lm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJFllViIGOy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example:\n",
        "lm = train_word_lm('../data/ptb.train.txt')\n",
        "lm.predict_next_word('Not')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF0DbCy4QwZz",
        "colab_type": "text"
      },
      "source": [
        "*1.2.2 How much memory do you expect a model to occupy? Refer to the statistics results above and provide worst-case estimates as well as expected.*\n",
        "\n",
        "**Answer:** For each bigram in the text, we a list of tuples - each the size of 2 (bigram) and a word after it.\n",
        "We can compute with the statistics the total number of distinct bigrams and multiply it by total number of distinct words in the corpus - that will be the worst case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kqHPsuWRcjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../data/ptb.train.txt','r') as file:\n",
        "  data = file.read()\n",
        "  print(dist_words(data))\n",
        "  print(dist_n_gram_words(data,n=[2]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaR5k81TYBNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perplexity(lm,'../data/ptb.test.txt',False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG7Lq2pP3ed-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy(lm,'../data/ptb.test.txt',False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATkR9e09X-3m",
        "colab_type": "text"
      },
      "source": [
        "##1.3.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KA6k5XVi3pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gamma_values = np.linspace(0.1,1,num=7)\n",
        "perplexity_values = []\n",
        "for gamma in gamma_values:\n",
        "  lm = train_word_gen('../data/ptb.train.txt',gamma=gamma)\n",
        "  perplexity_values += [perplexity(lm,'../data/ptb.valid.txt')]\n",
        "\n",
        "plt.plot(gamma_values,perplexity_values)\n",
        "#plt.loglog([val for word,val in collections.Counter(corpus).most_common(4000)])\n",
        "plt.xlabel('$\\gamma$')\n",
        "plt.ylabel('PERPLEXITY')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm7hvhDof1TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_gamma = 1 #according to the plot above\n",
        "\n",
        "n_values = list(range(2,20,2))\n",
        "perplexity_values = []\n",
        "for n in n_values:\n",
        "  lm = train_word_gen('../data/ptb.train.txt',n=n,gamma=best_gamma)\n",
        "  print (perplexity(lm,'../data/ptb.valid.txt',n=n))\n",
        "  perplexity_values += [perplexity(lm,'../data/ptb.valid.txt',n=n)]\n",
        "\n",
        "plt.plot(n_values,perplexity_values)\n",
        "#plt.loglog([val for word,val in collections.Counter(corpus).most_common(4000)])\n",
        "plt.xlabel('n')\n",
        "plt.ylabel('PERPLEXITY')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bObAunbNd86W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_n = 3\n",
        "best_gamma =1\n",
        "\n",
        "lm = train_word_gen('../data/ptb.train.txt',n=best_n,gamma=best_gamma)\n",
        "print(perplexity(lm,'../data/ptb.test.txt',n=best_n))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSvr9yXiniOW",
        "colab_type": "text"
      },
      "source": [
        "#TODO: for Nitzan\n",
        "1. Check what happens when for P(a|b) b=0 and specifically for our ngrams model\n",
        "2. Check with others about the perplexity when n>2\n",
        "3. compare perplexity graph accoridng to gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN2M2L6_hvrm",
        "colab_type": "text"
      },
      "source": [
        "1.3.2 Generating text\n",
        "\n",
        "Another way to evaluate a language model is to use the model in a generative manner - that is, to randomly sample sentences starting from a seed prefix, and generating each next word by sampling from the model distribution p(w | prefix).\n",
        "\n",
        "Discuss ways to generate when the seed is shorter than the history length of the n-gram model. Discuss ways to decide when the generation should stop. In this question, when you sample from the LM given a history, pick the most likely word generated by the LM. Report at least 5 randomly generated segments on different seeds and comment on what you observe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uShEeeSRhy3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model,seed):\n",
        "  p = 0\n",
        "  output = seed\n",
        "  while True:\n",
        "    next_word, prob = model.predict_next_word(seed)\n",
        "    output = ' '+ next_word\n",
        "    p+= prob\n",
        "    if p>=1:\n",
        "      break\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upDb2_qoujQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUmvvNzMuyhr",
        "colab_type": "text"
      },
      "source": [
        "##1.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OETOoJS0u1hB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download the dataset\n",
        "!wget http://www.ffts.com/recipes/lg/lg32965.zip\n",
        "!unzip lg32965 -d recipes_dataset\n",
        "!rm lg32965.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YliGO4-7wHZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare dataset\n",
        "with open('recipes_dataset/32965.mmf',errors='ignore') as file:\n",
        "  recipes=[]\n",
        "  collector = []\n",
        "  for line in file:\n",
        "    line = str(line).replace('MMMMM','')#.replace('\\n','')\n",
        "    if 'Recipe via Meal-Master (tm) v8.05' in line:\n",
        "      recipes += [''.join(collector)]\n",
        "      collector = []\n",
        "    else:\n",
        "      collector += [line]\n",
        "  recipes += [''.join(collector)]\n",
        "  recipes = recipes[1:]\n",
        "\n",
        "#print statistics\n",
        "total_recipes = ''.join(recipes)\n",
        "print('number of recipes',len(recipes))\n",
        "print('number of tokens',num_token(total_recipes))\n",
        "print('number of characters',num_char(total_recipes))\n",
        "print('vocabulary size',dist_words(total_recipes))\n",
        "print('avg word count',float(np.mean([num_token(rec) for rec in recipes])))\n",
        "print('avg word length')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZIHQhbqQf6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataLoader():\n",
        "\n",
        "  def __init__(self,dataset):\n",
        "    from math import floor,ceil\n",
        "\n",
        "    self.train_data = dataset[0:floor(0.8*len(dataset))]\n",
        "    self.valid_data = dataset[ceil(0.8*len(dataset)):floor(-0.1*len(dataset))]\n",
        "    self.test_data = dataset[ceil(-0.1*len(dataset)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD2UKmNwQgrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = MyDataLoader(recipes)\n",
        "joined_recipes_train = ''.join(dataloader.train_data)\n",
        "joined_recipes_test = ''.join(dataloader.test_data)\n",
        "joined_recipes_val = ''.join(dataloader.valid_data)\n",
        "\n",
        "# with open('tmp_train.txt', \"w\") as text_file:\n",
        "#   text_file.write(joined_recipes_train)\n",
        "# with open('tmp_test.txt', \"w\") as text_file:\n",
        "#   text_file.write(joined_recipes_test)\n",
        "\n",
        "#using Ben Eyal's implementation for chars lang. model\n",
        "\n",
        "\n",
        "def create_lm(data, n=5):\n",
        "    pad = '$' * (n-1)\n",
        "    data = pad + data\n",
        "    cfd = nltk.ConditionalFreqDist((data[i : i + n-1], data[i + n-1]) for i in range(len(data) - (n-1)))\n",
        "    cpd = nltk.ConditionalProbDist(cfd, nltk.MLEProbDist)\n",
        "    return cpd\n",
        "\n",
        "def chars_generate(lm,n,num_chars):\n",
        "  import string\n",
        "  import random\n",
        "\n",
        "  out = []\n",
        "  hist = '$' * (n-1)\n",
        "  for _ in range(num_chars):\n",
        "      try:\n",
        "        #print(hist)\n",
        "        #print(lm[hist])\n",
        "        letter = lm[hist].generate()\n",
        "      except:\n",
        "        break\n",
        "      hist = hist[1:] + letter\n",
        "      out.append(letter)\n",
        "  print(''.join(out))\n",
        "\n",
        "def chars_perplexity(lm,data,n):\n",
        "  answer = 1\n",
        "  for i in range(len(data) - (n+1)):\n",
        "      prev_chars = data[i:i+n-1]\n",
        "      next_char= data[i+n-1]\n",
        "      eval = lm[prev_chars].prob(next_char)\n",
        "      if eval==0:\n",
        "        eval = 1/(128) #ascii (smoothing)\n",
        "      if eval!=0:\n",
        "        eval = (1/(eval)) **(1/len(data))\n",
        "        answer*= eval\n",
        "  return answer  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNoqJZK8Ehnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_values = list(range(2,20,2))\n",
        "perplexity_values = []\n",
        "for n in n_values:\n",
        "  lm = create_lm(joined_recipes_train,n=n)\n",
        "  perplexity_values += [chars_perplexity(lm,joined_recipes_val,n=n)]\n",
        "\n",
        "plt.plot(n_values,perplexity_values)\n",
        "plt.xlabel('n')\n",
        "plt.ylabel('PERPLEXITY')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io0MYhLtKRFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_n = 6 #according to the graph\n",
        "\n",
        "lm = create_lm(joined_recipes_train, n=best_n)\n",
        "num_chars = int(np.mean([num_char(rec) for rec in dataloader.test_data]))\n",
        "chars_generate(lm,best_n,num_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU54BptM1u6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars_generate(lm,best_n,num_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXu7z1qZ74dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars_generate(lm,best_n,num_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwzKLc4R75Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars_generate(lm,best_n,num_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnleYE677RU",
        "colab_type": "text"
      },
      "source": [
        "###Observations\n",
        "We can see that the LM's dist. can 'understand' the structure of recipes. That is, understand a syntax similar to [amount] [unit] [ingredient] [activity]* \n",
        "\n",
        "We also observe that some ingredient typically occure in the beginning, such as Oregano, we have no idea why it happens.\n",
        "\n",
        "The model doesn't do indendation like the dataset. It doesn't finish some sentences.\n",
        "\n",
        "Although the model is for characters, we can see that it's not completely gibberish, there are many real English words that appear semantically in the vocabullary of recipes, as we expected.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlcNOpk987Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMvIhgoW9tC_",
        "colab_type": "text"
      },
      "source": [
        "#Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCc1F4Lv_1uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy.linalg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrHiKNiP9wz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateDataset(N, f, sigma):\n",
        "  mu = 0.0\n",
        "  vf = np.vectorize(f)\n",
        "  x = np.linspace(0,1,num=N)\n",
        "  noise = np.random.normal(loc=mu,scale=sigma,size=N)\n",
        "  t = vf(x) + noise\n",
        "  return (x,t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbNxOkBS-4by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sanity check\n",
        "f = lambda x : math.sin(math.pi * 2 * x)\n",
        "plt.plot(*generateDataset(10,f,0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85QvFT9V_cmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def OptimizeLS(x, t, M):                      \n",
        "  phi = np.vander(x,M+1,True)\n",
        "  prod = np.dot(phi.T, phi)             \n",
        "  i = np.linalg.inv(prod)\n",
        "  m = np.dot(i, phi.T)\n",
        "  w = np.dot(m, t)\n",
        "  return w                                                              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VESXd4j6u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.vander([1,2,3,4],3,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYNkVAzeQcsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x,t) = generateDataset(10,f,0.1)\n",
        "plt.plot(x,t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_TiMtzM_zbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 10\n",
        "get_y = lambda w,M: lambda x: sum([w[i]*(x**i) for i in range(M+1)])\n",
        "(x,t) = generateDataset(N,f,0.03)\n",
        "plt.plot(x,t)\n",
        "for M in [1,3,5,10]:\n",
        "  w = OptimizeLS(x,t,M)\n",
        "  y_hat = np.vectorize(get_y(w,M))\n",
        "  plt.plot(x,y_hat(x))\n",
        "plt.legend(['sin(2*pi*x)+noise','y_hat_1','y_hat_3','y_hat_5','y_hat_10'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjT_hZugwvHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHf9K1YamqRk",
        "colab_type": "text"
      },
      "source": [
        "##2.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVW6mFTHHmSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateDataset3(N,f,sigma):\n",
        "  from math import ceil,floor\n",
        "  mu = 0.0\n",
        "  vf = np.vectorize(f)\n",
        "  x = np.linspace(0,1,num=N*3)\n",
        "\n",
        "  noise = np.random.normal(loc=mu,scale=sigma,size=N*3)\n",
        "  t = vf(x) + noise\n",
        "  pairs = list(zip(x,t))\n",
        "  #print(list(zip(x,t)))\n",
        "  np.random.shuffle(pairs)\n",
        "  #print(pairs)\n",
        "  def sort_by_x(lst):\n",
        "    return sorted(lst,key=lambda x : x[0])\n",
        "  train = sort_by_x(pairs[0:N])\n",
        "  valid = sort_by_x(pairs[N:2*N])\n",
        "  test = sort_by_x(pairs[2*N:])\n",
        "  return train,valid,test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNERrMn5ouNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c = generateDataset3(10,f,0.1)\n",
        "a_x = [x for x,_ in a]\n",
        "a_y = [y for _,y in a]\n",
        "plt.plot(a_x,a_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyXt65LQsdHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizePLS(x, t, M, _lambda):\n",
        "  phi = np.vander(x,M+1,True)\n",
        "  prod = np.dot(phi.T, phi)\n",
        "  lambda_mat = np.eye(M+1)*_lambda + prod\n",
        "  i = np.linalg.inv(lambda_mat)\n",
        "  m = np.dot(i, phi.T)\n",
        "  w = np.dot(m, t)\n",
        "  return w   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-EiTzho1M0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizePLS2(xt, tt, xv, tv, M):\n",
        "  N = len(xt)\n",
        "  min_error  = [1,1,float(\"inf\")]\n",
        "  for log_lambda in range(-40,-20):\n",
        "    w = optimizePLS(xt,tt,M,2**log_lambda)\n",
        "    error = calculate_error(w,xv,tv)\n",
        "    if error<min_error[2]:\n",
        "      min_error = [2**log_lambda,w,error]\n",
        "  print('chosen lambda',min_error[0])\n",
        "  return min_error[0],w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnwps6fCpjxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_error(w,x,y):\n",
        "  poly = np.vectorize(get_y(w,M))\n",
        "  poly = poly(x)\n",
        "  power2 = lambda x : x**2\n",
        "  error = (1/N)*(sum(power2(y - poly)))**(1/2)\n",
        "  return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEfnjJ900ECW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for N in [10,100]:\n",
        "  (train,val,test) = generateDataset3(N,f,0.03)\n",
        "  xt = [x for x,_ in train]\n",
        "  tt = [x for _,x in train]\n",
        "  xv = [x for x,_ in val]\n",
        "  tv = [x for _,x in val]\n",
        "  xtest = [x for x,_ in test]\n",
        "  ttest = [x for _,x in test]\n",
        "  M = N - 1\n",
        "  _,w = optimizePLS2(xt,tt,xv,tv,M)\n",
        "  plt.scatter(N,calculate_error(w,xt,tt))\n",
        "  plt.scatter(N,calculate_error(w,xv,tv))\n",
        "  plt.scatter(N,calculate_error(w,xtest,ttest))\n",
        "plt.legend(['train','valid','test','train','valid','test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At9URsDOXiK7",
        "colab_type": "text"
      },
      "source": [
        "##2.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERjWNq-bTDTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def bayesianEst(x,t,M,alpha,sigma2):\n",
        "  phi = lambda x : np.array([x**i for i in range(M+1)]).T\n",
        "  N = len(x)\n",
        "  collect_vectors = [phi(xi) for xi in x]\n",
        "  phi_mat = np.matrix(collect_vectors)\n",
        "  S_inv = alpha*np.eye(M+1) + phi_mat*phi_mat.T\n",
        "  S = np.linalg.inv(S_inv)\n",
        "  def mean(xi):\n",
        "    sumX = np.array(np.zeros((M+1, 1)))\n",
        "    for n in range(N):\n",
        "      sumX += phi_mat[n].T* t[n]\n",
        "    return (1/sigma2)*phi(xi).T*S*sumX\n",
        "  \n",
        "  def variance(x):\n",
        "    return sigma2**2 + (phi(x).T)@S@phi(x)\n",
        "    \n",
        "  return (mean,variance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwM6d2Ob1he",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c01acacf-5b4c-421e-a8e4-0ec468c35d95"
      },
      "source": [
        "m,v = bayesianEst([1,2,3],[1,2,3],2,0,0.1)\n",
        "print(m(1))\n",
        "print(v(1))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[120.]]\n",
            "[[1.01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOdkcO2GUGrO",
        "colab_type": "text"
      },
      "source": [
        "m,v = bayesianEst([1,2,3],[1,2,3],2,0,0.1)\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "v(1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1W2cSId31Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bayesianEstimator(x, t, M, alpha, sigma2):\n",
        "  t_vec = np.asarray(t).T\n",
        "  N = len(x)\n",
        "  print(t_vec.shape)\n",
        "  phi = np.vander(x,M+1,True)\n",
        "  #print(phi)\n",
        "  phi_ = lambda x : np.array([x**i for i in range(M+1)]).T\n",
        "  S_inv = alpha*np.eye(M+1) + (1/sigma2)*np.dot(phi.T,phi)\n",
        "  S = np.linalg.inv(S_inv)\n",
        "  def m(x):\n",
        "    a = (1/sigma2)*phi_(x).T\n",
        "    print(a)\n",
        "    print(phi[:,0:N].shape)\n",
        "    b = phi[:,0:N]@t_vec\n",
        "    return a@S@b\n",
        "\n",
        "  #m = lambda x : (1/sigma2)*(phi_(x).T@S@ phi[1:N,:]@t_vec)\n",
        "  s2 = lambda x : sigma2 + phi_(x).T@S@phi_(x)\n",
        "  return (m,s2)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0OxclqmbuhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24348e89-e122-4acc-a6e4-1500483aac46"
      },
      "source": [
        "h = list(range(100))\n",
        "m,var = bayesianEstimator(h,h,2,0.1,0.1)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxrHM5JZe3E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "f1113cb8-36e1-47dc-9645-dd5b2eaeaeb9"
      },
      "source": [
        "m(1)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10. 10. 10.]\n",
            "(100, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-c0fc02733ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-97-355a720921fa>\u001b[0m in \u001b[0;36mm\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mt_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 100 is different from 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLPTG6_BfBkC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52037681-c2ff-4b69-8508-c3c11515d961"
      },
      "source": [
        "var(1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18913876122536905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gmxV9PhCE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}